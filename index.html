<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="University of Wisconsin, Madison">
    <meta name="author" content="Chaowei Xiao">

    <title>Chaowei Xiao, University of Wisconsin, Madison</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/small-business.css" rel="stylesheet">
    <style type="text/css">
      .content{margin-top: 0; margin-bottom: 0}
    </style>
    <meta http-equiv="Content-Type" content="text/html; charset=gbk"> 
    <meta name="google-site-verification" content="qEih9m0y-6X0QuisQYfHSxOvkW-o5Q3dfxuQ5Z4JtGA" />

  </head>

  <body>

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
      <div class="container">
        <a class="navbar-brand" href="#">Home</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item active">
              <a class="nav-link" href="#">Home
                <span class="sr-only">(current)</span>
              </a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#about">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="https://xiaocw11.github.io/full.html">Publications</a>
            </li>
          
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Content -->
    <div class="container">

      <!-- Heading Row -->
      <div class="row my-4">
        <div class="col-lg-4">
          <img class="img-fluid rounded img-responsive" style="width:80%" src="img/avatar_new.jpg" alt="">
        </div>
        <!-- /.col-lg-8 -->
        <div class="col-lg-8">
          <h3>Chaowei Xiao </h3>
          <!-- <p>PhD Candidate</p>
          <p>Room 3944, Beyster Building</p>
          <p>2260 Hayward Street, Ann Arbor, Mi 48109</p>
           -->
          <p>Email: cxiao34@wisc.edu</p>
          <p class=" m-0">I am Chaowei Xiao, an assistant professor at the University of Wisconsin, Madison, and  a <a href="https://research.nvidia.com/labs/avg/"> research scientist at NVIDIA </a>.
            
            <!-- I obtained my PhD degree from  University of Michigan, Ann Arbor under supervision of Professor <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> . I obtained my bachelor's degree in School of Software from Tsinghua University in 2015.  -->
            <!-- advised by Professor <a href="http://www.cse.msu.edu/~liuyunha/">Yunhao Liu</a>, Professor <a href="http://www.thss.tsinghua.edu.cn/publish/soft/3641/2013/20130711150050931989171/20130711150050931989171_.html">Zheng Yang</a> and Dr. <a href="http://www4.comp.polyu.edu.hk/~csyanglei/#/pages/profile/about">Lei Yang</a>.  -->
            <!-- I was also a visiting student at UC Berkeley in 2018, advised by Professor <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p> -->
          <p></p>
          <p class="m-0">I am currently very interested in exploring the safety and security of Large Language Model Systems and studying the role of LLMs in different application domains. </p>
          <!-- <p class="m-0" style="color:red">I am on the job marketing.</p> -->
          <br>
          <!-- <p class="m-0"> <font color='red' >I will be joining Arizona State University  as  an assistant professor in the  School of Computing, Informatics, and Decision Systems Engineering in the Fall of 2021. </font> </p> -->

          <!-- <p class="m-0"><a href="https://scholar.google.com/citations?user=Juoqtj8AAAAJ&hl=en">[Google Scholar] </a><a href="pdf/cv_chaoweixiao_new.pdf">[CV] </a></p> -->
          <p class="m-0"> I obtained my Ph.D. from  the University of Michigan, Ann Arbor, and my bachelor's degree from Tsinghua University. Before joining UW-Madison, I spent two years at NVIDIA as a full-time research scientist and a wonderful year at ASU. 
             <!-- Professor <a href="http://www.thss.tsinghua.edu.cn/publish/soft/3641/2013/20130711150050931989171/20130711150050931989171_.html">Zheng Yang</a> and Dr. <a href="http://www4.comp.polyu.edu.hk/~csyanglei/#/pages/profile/about">Lei Yang</a>.  -->
          </p>
          <p class="m-0"><a href="https://scholar.google.com/citations?user=Juoqtj8AAAAJ&hl=en">[Google Scholar] </a> <a href="https://safolab-wisc.github.io/"> [Group Website]</a></p>
<!--           <p> <font color='blue' >
            
            Iâ€™m looking for self-motivated students (B.S., Master, and Ph.D.) who are interested in my research. If you are interested in working with me, drop me an email with your CV. Check out our PhD programs at <a href="https://guide.wisc.edu/graduate/computer-sciences/computer-sciences-phd/"> Computer Science </a>  or  <a href="https://ischool.wisc.edu/programs/phd/"> Information School </a> @ University of Wisconsin Madison and mention my name in your application and research statement.  
  
          </font></p> 
          <p> <font color='red' >
          Our group plans to recruit at least 2-3 PhD students in the coming years with full financial  support.
   </font></p> 
          </font></p> 
           <p> <font color='blue' >
          UW-Madison is an excellent place for research, and Madison is a wonderful city to live in. Please check out these videos (Why <a href="https://www.youtube.com/watch?v=8cRE4F8GOBE">UW-Madison</a>,<a href="https://www.youtube.com/watch?v=XTJA5alrisQ?"> Madison</a>).
   </font></p> 
          </font></p> 

          <br> -->
          <!-- <a class="btn btn-primary btn-lg" href="#">Call to Action!</a> -->


<!-- Due to the large amount of emails I receive, I may not be able to respond to each one individually. -->
        </div>
        <!-- /.col-md-4 -->
      </div>
      <!-- /.row -->
       <div class=" my-4 text-left">
      <h4>Award</h4>
      <ul>
         <li> <a href="https://www.usenix.org/conference/usenixsecurity24/presentation/yu-zhiyuan" > <font color='red' >[2024] USENIX Security Distinguished Paper Award.</font></a> </li>
         <li>  <a href="https://ai2050.schmidtsciences.org/fellows/"><font color='red' > [2024] Schmidt Sciences  AI2050 Early Career Fellow </font></a></li>
         <li> <a href="https://sc24.supercomputing.org/2024/10/presenting-the-finalists-for-the-2024-gordon-bell-prize/"> [2024] ACM Gordon Bell Final list</a> </li>
         <li> <a href="https://blogs.nvidia.com/blog/graduate-fellowship-recipients-2025-2026/"> [2024] My PhD student Xiaogeng Won NVIDIA Fellowship on Security track </a> </li>
         <li> <a href="https://top2percentscientists.com/stanford-elsevier-top-scientists-list-2024/"> [2024] Selected in Stanford/Elsevier Top 2% Scientists List 2024</a> </li>
         <li>  [2023] ACM Gordon Bell Special Prize for HPC-Based COVID-19 Research</li>
         <li>  [2023] Impact Award from Argonne National Laboratory. </li>
         <li> [2021] International Confrence on Embedded Wireless Systems and Networks(EWSN) Best Paper Award </li>
         <li> [2014] MobiCom Best Paper Award</li>        
      </ul>
       </div>
      <div class=" my-4 text-left">
      <h4>Recent Invited talks</h4>
      <ul>
        <li> [12/2024] Invited talk at SFU@NeurIPS</li>
        <li> [12/2024] Invited talk at LLM and Agent Safety Competition@NeurIPS.</li>
        <li> [10/2024] Keynote at <a href="https://lamps-ccs.com/">CCS Workshop on
Large AI Systems and Models with Privacy and Safety Analysis</a>.  </li>
        <li> [10/2024] Invited talk at Trillion Parameter Consortium (TPC) on LLM safety and security</li>
          <li> [10/2024] Invited talk at <a href="https://nyu-larx.github.io/nsf-llm4security/#Agenda">NSF Workshop on Large Language Models for Network Security  </a></li>
    <li> [06/2024] Invited talk at CVPR Workshop of Adversarial Machine Learning on Computer Vision: Robustness of Foundation Models</li>
        <li> [06/2024] Talk at NAACL tutorial on Combating Security and Privacy Issues in the Era of Large Language Models </li>
        <li> [05/2024] Invited talk at ICLR Secure and Trustworthy Large Language Models </li>
         <li> [12/2023] Invited Talk at NeurIPS TDW workshop </li>
      </ul>
       </div>
    <div class=" my-4 text-left">
      <h4>Recent News</h4>
      <ul>
        <li style="display:none "> <a href="cv_chaoweixiao_Feb.pdf">package</a> </li>
        <li style="display:none "> <a href="package_ChaoweiXiao.pdf">package</a> </li>

        <li> [1/2025] We have 9 papers at ICLR and 3 papers at NAACL on  Model Safety and Security. Congratulations  to all authors. </li>
        <li> [12/2024] I will give an invited talk at SFU@NeurIPS and  LLM and Agent Safety Competition at NeurIPS.</li>
            <li> [12/2024] We got the Fall Research Competition Award at UW-Madison. Thank you UW-Madison and OVCR. </li>
                     <li> [11/2024] Our group recently received funding and donations. Thank you Amazon and Apple. </li>
                  <li>[11/2024] Our lab will have a winter break this Dec. Lab members will  enjoy some well-deserved vacation time, with their families and loved ones.  </li> 
             <li> [09/2024] We have four papers at NeurIPS regular track.</li>
             <li> [09/2024]Our study on  <a href="https://arxiv.org/abs/2402.01920"> safety of RLFH Alignment  </a> is accepted to S&P (Oakland) 2025 </li>
             <li> [07/2024] <a href="https://eddyluo1232.github.io/JailBreakV28K/">MultiModal jailbreak benchmark </a> is accepted to COLM. It is from the interns in my group.  </li>

     <li> [07/2024] 4/4 papers are accepted to ECCV on the topic of trustworthy VLM and driving. Two of them are from  interns in my group.  </li>
        <li> [06/2024] Senior Area Chair for NeurIPS Benchmark track</li>
        <li> [06/2024] I am currently serving as AC for the NeurIPS regular track </li>
        <li> [05/2024] Our jailbreak paper is accepted to USENIX Security. Congratulations, Zhiyuan! </li>
        <li> [03/2024] Five papers at NAACL on LLM security (4 main and 1 finding): two on the backdoor attack, one on backdoor defense, one on jailbreak attacks, and one on model fingerprint.  Stay tuned on these exciting fields </li>
        <li> [03/2024] PreDa for personalized federated learning is accepted at CVPR 2024. </li>      
        <li> [01/2024] Three papers at ICLR. </li>
           <li> [01/2024] Two papers at TMLR </li>
         <li> [12/2023] Invited Talk at NeurIPS TDW workshop </li>
      
        <li> [10/2023]Our paper MoleculeSTM has been accepted to Nature Machine Intelligence. MoleculeSTM aims to align the nature language and molecule representation into the same representation space.  </li> 
                 <details>
            <summary>More</summary>
        <li> [10/2023] Three papers at EMNLP and one paper at NeurIPS. For our NeurIPS paper, we study a new threat of the instruction tuning of LLMs by injecting the Ads. This is the first work that views the LLMs as the generative model and aims  to attack the generative property of LLMs.  </li> 
         <li> [10/2023] Our tutorial on Security and Privacy in the Era of Large Language Models is accepted to NAACL.  </li> 
        <li> [05/2023] One paper at ACL.  Congratulations to zhuofeng and jiazhao. We propose an attention-based method to defend against NLP backdoor attacks </li>
        <li> [04/2023] Two papers at ICML. Congratulations to Jiachen and Zhiyuan. We propose the first benchmark for code copyright of code generation models.</li>
        <li> [02/2023] Two papers at CVPR. Congratulations to Yiming and Xiaogeng. Xiaogeng is an intern from my group at ASU. </li>
        <li> [02/2023] I will give a tutorial at CVPR 2023 on the topic of trustworthiness in the era of Foundation Models. Stay tuned!</li>
        <li> [01/2023] <a href="impact.pdf">Impact Award from Argonne National Laboratory.</a> </li>
        <li> [01/2023] One paper got accepted to USENIX Security 2023. </li>
        <li> [1/2023] Three papers are accepted to ICLR 2023 <a href="https://arxiv.org/abs/2211.00322">[a]: </a>We explain why and how to use diffusion model to improve adversarial robustness and design DensePure which leverages the pretrained diffusion model and classifier to provide the state-of-the-art certified robustness. <a href="https://arxiv.org/pdf/2208.11126.pdf">[b]:</a>This is our first attemp on  retrieval-based framework and AI for drug discovery. We will recently release more work in this research line. Stay tuned! </li>
        <li> [12/2022] Our team won the ACM Gordon Bell Special Prize for COVID-19 Research.</li>
        <li> [09/2022] One papers got accepted to USENIX Security 2023.</li>
        <li> [09/2022] Two papers got accepted to  NeurIPS 2022.</li>
        <li> [09/2022] Our paper <a href="https://arxiv.org/pdf/2208.00094.pdf">RobustTraj</a> has been accepted to CORL for oral presentations. We explore to train a robust Trajectory Prediction Model against adversarial attacks.</li>
 
        <li> [08/2022] I will be giving a talk in virtual seminar series on 
          <a href="https://vsehwag.github.io/SPML_seminar/" > Challenges and Opportunities for Security & Privacy in Machine Learning.</a>
        <li> [07/2022] One survey paper to discuss the challenge and opportunity of machine learning security got accepted to ACM Computing Survey 2022.  
        <li> [07/2022] Two papers got accepted to ECCV 2022.  </li>
        <li> [05/2022] Two papers got accepted to ICML 2022. Thanks for all of my collaborators. </li>
        <li> [3/2022]  I will be giving a talk in AAAI 2022 1st International Workshop on Practical Deep Learning in the Wild.</li>
        <li> [3/2022] I will be giving a talk in AAAI 2022 workshop on Adversarial Machine Learning and Beyond. </li>

          <li> [2/2022] One paper is accepted to ICLR. </li>
      </details>
    </ul>
      <!-- <p> [07/2019]: Our paper "AdvIT: Adversarial Frames Identifier Based on Temporal Consistency In Videos" is accepted to ICCV 2019. </p>  -->
         <!-- <p>  [06/2019]: Our paper: <a href="https://arxiv.org/abs/1907.05418"> "Adversarial Objects Against LiDAR-Based Autonomous Driving Systems" </a> is reported by <a href="https://syncedreview.com/2019/07/18/researchers-fool-lidar-with-3d-printed-adversarial-objects/"> Syncedreview</a>, <a href="https://www.selfdrivingcars360.com/researchers-fool-lidar-with-3d-printed-adversarial-objects/">Selfdrivingcars360</a>, <a href="https://www.analyticsindiamag.com/lidar-adversarial-objects-research-vulnerabilities-drawbacks/amp/">Analytics</a> and is discussed at <a href="https://www.reddit.com/r/SelfDrivingCars/comments/cc7khu/adversarial_objects_against_lidarbased_autonomous/">Reddit [1]</a>, <a href="https://www.reddit.com/r/MachineLearning/comments/ccc7p4/r_we_also_3dprint_our_adversarial_objects_and/">[2]</a>.</p> -->
      <!-- <p> [05/2019]: One paper is accepted to CCS 2019. </p>  -->
      <!-- <p> [05/2019]: One paper is accepted to USENIX Security 2019.  </p>  -->

<!--       <p> [03/2019]: I will serve as a Program Committee member of <a href="https://icml2019workshop.github.io/">Security and Privacy of Machine Learning workshop </a> at ICML 2019.</p>  
 -->
      </div>

<!--     <div class="my-4 text-left">    
      <h4>Current PhD Students:</h4>  
       <ul>
            <li><a href="https://jiongxiao-wang.github.io/"> Jiongxiao Wang </a> </li>
            <li><a href="https://sheltonliu-n.github.io/"> Xiaogeng Liu</a></li>
            <li><a href="https://cychomatica.github.io/"> Shutong Wu </a></li>
            <li><a href=""> Fangzhou Wu</a> </li>
        </ul>
   
    </div> -->
<!--     <div class="my-4 text-left">    
      <h4> Research Overview</h4>  
      <img class="col-lg-8" src="framework.png" alt="research overview">
    </div> -->
      <!-- Call to Action Well -->
<!--       <div class=" my-4 text-left">
          <h4 id="about">About</h4>
          <p class=" m-0">I am<strong>Chaowei Xiao</strong>, a final year PhD student in CSE Department, University of Michigan, Ann Arbor. My advisor is Professor <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> . I obtained my bachelor's degree in School of Software from Tsinghua University in 2015, advised by Professor <a href="http://www.cse.msu.edu/~liuyunha/">Yunhao Liu</a>, Professor <a href="http://www.thss.tsinghua.edu.cn/publish/soft/3641/2013/20130711150050931989171/20130711150050931989171_.html">Zheng Yang</a> and Dr. <a href="http://www4.comp.polyu.edu.hk/~csyanglei/#/pages/profile/about">Lei Yang</a>. I was also a visiting student at UC Berkeley in 2018, advised by Professor <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a> and Professor <a href="http://boli.cs.illinois.edu/">Bo Li</a>. </p>
          <p></p>
          <p class="m-0">My research interest includes adversarial machine learning. </p>


      </div> -->
      <!-- <div class="my-4 text-left">
        <h4>Current Students (Collaborators) </h4>
        <ul>
            <li><a href=""> Yulong Cao </a> (affiliated Ph.D. student from University of Michigan, Ann Arbor)</li>
            <li><a href=""> Jiachen Sun</a> (affiliated Ph.D. student from University of Michigan, Ann Arbor)</li>
            <li><a href=""> Haizhong Zheng </a> (affiliated Ph.D. student from University of Michigan, Ann Arbor)</li>
            <li><a href=""> Jiazhao Li </a> (affiliated Ph.D. student from University of Michigan, Ann Arbor)</li>
        </ul>
      </div>
      <div class="my-4 text-left">
        <h4>Past Students</h4>
        <ul>
            <li><a href=""> Zichao Li</a> (now Ph.D. student from UCSC)</li>
            <li><a href=""> Haonan Qiu</a> (now Ph.D. student from NTU)</li>
        </ul>
      </div> -->



   <div class=" my-4 text-left">      
<!-- <div class="card-body"> -->
          <h4 id="pub"> Preprints </h4>
       <ul>

          <li><b> [New][Agent Security] A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems. </b><p class='content'> Fangzhou Wu, Ning Zhang, Somesh Jha, Patrick McDaniel, Chaowei Xiao. </p><a href="https://arxiv.org/abs/2402.18649">https://arxiv.org/abs/2402.18649</a></li>
 

       </ul>
         <h4 id="pub">Selected Publications (<a href="full.html">[Full List]</a>)  </h4>
           <p>(* represents equal contribution) </p>
           <p> <a href="https://scholar.google.com/citations?user=Juoqtj8AAAAJ&hl=en">[Google Scholar]</a></p>
      <!-- <h5> 2023</h5> -->
         <ul>
            </p> <a href="">ICLR 2024</a> </li>
           <li><b>[LLM Security] AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs
 </b> <p class='content'> Xiaogeng Liu, Peiran Li, G. Edward Suh, Yevgeniy Vorobeychik, Zhuoqing Mao, Somesh Jha, Patrick McDaniel, Huan Sun, Bo Li, Chaowei Xiao
</p> <a href="">ICLR 2024</a> </li>
           <li><b>[LLM Security]Can Watermarks be Used to Detect LLM IP Infringement For Free?  </b> <p class='content'> Zhengyue Zhao, Xiaogeng Liu, Somesh Jha, Patrick McDaniel, Bo Li, Chaowei Xiao
</p> <a href="">ICLR 2024</a> </li>
           <li><b>[Agent Security] EIA: Environmental Injection Attack on Generalist Web Agent for Privacy Leakage.  </b> <p class='content'> Zeyi Liao, Lingbo Mo, Chejian Xu, Mintong Kang, Jiawei Zhang, Chaowei Xiao, Yuan Tian, Bo Li, Huan Sun
           <li><b>[LLM for Science]LeanAgent: Lifelong Learning for Formal Theorem Proving.  </b> <p class='content'> Adarsh Kumarappan, Mo Tiwari, Peiyang Song, Robert Joseph George, Chaowei Xiao, Anima Anandkumar. </p> <a href="">ICLR 2024</a> </li>

   <li><b>[LLM Safety (Hallucination)]HaloScope: Harnessing Unlabeled LLM Generations for Hallucination Detection.  </b> <p class='content'> Xuefeng Du, Chaowei Xiao, Yixuan Li
</p> <a href="https://arxiv.org/abs/2409.17504">NeurIPS 2024 (Oral)</a> </li>
           
                <li><b>[LLM Security] Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment.  </b> <p class='content'> Jiongxiao Wang, Jiazhao Li, Yiquan Li, Xiangyu Qi, Muhao Chen, Junjie Hu, Yixuan Li, Bo Li, Chaowei Xiao
</p> <a href="https://arxiv.org/abs/2402.14968">NeurIPS 2024</a> </li>
         <li><b>[LLM For Driving] Dolphins: Multimodal Language Model for Driving.  </b> <p class='content'>  Yingzi Ma, Yulong Cao, Jiachen Sun, Marco Pavone, Chaowei Xiao</p> <a href="https://arxiv.org/abs/2312.00438"> ECCV 2024</a> </li>     

       <li><b> [ Embodied Agent] Voyager: An Open-Ended Embodied Agent with Large Language Models.  </b> <p class='content'>  Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, Anima Anandkumar
</p> <a> TMLR 2024</a> </li>     

            <li><b>[LLM Fingerprint]Instructional fingerprinting of large language models.  </b> <p class='content'>  Jiashu Xu, Fei Wang, Mingyu Derek Ma, Pang Wei Koh, Chaowei Xiao, Muhao Chen.</p> <a href="https://arxiv.org/abs/2401.12255">NAACL 2024.</a> </li>

            <li><b>[LLM Security]AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models.  </b> <p class='content'>  Xiaogeng Liu, Nan Xu, Muhao Chen, Chaowei Xiao.</p> <a href="https://arxiv.org/pdf/2310.04451.pdf">ICLR 2024.</a> </li>

          <li><b>[LLM Security]On the exploitability of instruction tuning.  </b> <p class='content'>  Manli Shu, Jiongxiao Wang, Chen Zhu, Jonas Geiping, Chaowei Xiao*, Tom Goldstein*. <p>NeurIPS   2023 <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
          <li><b>[LLM Copyright]CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models          </b> <p class='content'> Zhiyuan Yu, Yuhao Wu, Ning Zhang, Chenguang Wang, Yevgeniy Vorobeychik, <strong>Chaowei Xiao</strong><p>ICML   2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
          <li><b>  [Diffusion & Security] Diffusion Models for Adversarial Purification</b> <p class='content'>Weili Nie, Brandon Guo, Yujia Huang,<strong>Chaowei Xiao</strong>, Arash Vahdat, Anima Anandkumar. <p>ICML 2022<a href="https://arxiv.org/abs/2205.07460">[pdf]</a> <a href="https://github.com/NVlabs/DiffPure">[code]</a></p></p></li>         
         <li><b>[Diffusion & Security]  DensePure: Understanding Diffusion Models towards Adversarial Robustness. </b> <p class='content'>  <strong>Chaowei Xiao</strong>*, Zhongzhu Chen*, Kun Jin*, Jiongxiao Wang*, Weili Nie, Mingyan Liu, Anima Anandkumar, Bo Li, Dawn Song  <p>ICLR  2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
          
          <li><b>  [ViT & Robustness] Understanding the robustness in vision transformers.</b> <p class='content'>Daquan Zhou, Zhiding Yu, Enze Xie,<strong>Chaowei Xiao</strong>, Anima Anandkumar, Jiashi Feng, Jose M Alvarez.<p>ICML 2022<a href="https://arxiv.org/abs/2204.12451">[pdf]</a> <a href="https://github.com/NVlabs/FAN">[code]</a></p></p></li>
          
<!-- 
          <li><b> [Security] AdvDO: Realistic Adversarial Attacks for
            Trajectory Prediction</b> <p class='content'>Yulong Cao,<strong>Chaowei Xiao</strong>, Anima Anandkumar, Danfei Xu,
              Marco Pavone.<p>ECCV 2022<a href="">[pdf]</a> <a href="">[code]</a></p></p></li> -->


          <!-- <li><b> SecretGen: Privacy Recovery on Pre-trained Models</b> <p class='content'>Zhuowen Yuan, Fan Wu, Yunhui Long,<strong>Chaowei Xiao</strong>, Bo Li<p>ECCV 2022<a href="">[pdf]</a> <a href="">[code]</a></p></p></li> -->
          
     


          <!-- <li><b>[Robustness] RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning</b><p class='content'> Xiaojian Ma, Weili Nie, Zhiding Yu, Huaizu Jiang,<strong>Chaowei Xiao</strong>, Yuke Zhu, Song-Chun Zhu, Anima Anandkumar <p>ICLR 2022<a href="https://web.cs.ucla.edu/~xm/file/relvit_iclr22.pdf">[pdf]</a> <a href="https://github.com/NVlabs/RelViT">[code]</a></p></p></li> -->
          
          <!-- <li><b> Characterizing Attacks on Deep Reinforcement Learning. </b> <p class='content'>Xinlei Pan*,<strong>Chaowei Xiao</strong>*, Warren He, Shuang Yang, Peng Jian, Mingjie Sun, Mingyan Liu, Bo Li, Dawn Song.  <p>AAMAS 2022 <a href="pdf/aamas_2022.pdf">[pdf]</a></p></p></li> -->

            <!-- </ul> -->
          <!-- <h5>2021</h5> -->
          <!-- <ul> -->
          <li><b>[Robustness] AugMax: Adversarial Composition of RandomAugmentations for Robust Training. </b> <p class='content'>Haotao Wang,<strong>Chaowei Xiao</strong>, Jean Kossaifi, Zhiding Yu, Animashree Anandkumar,  Zhangyang Wang.  <p>NeurIPS 2021</p></p></li>
         
          <!-- <li><b> Efficient Transformers for Language and Vision. </b> <p class='content'>Chen Zhu, Wei Ping,<strong>Chaowei Xiao</strong>, Mohammad Shoeybi, Tom Goldstein, Anima Anandkumar, Bryan Catanzaro. <p>NeurIPS 2021 (84.1% Top-1 accuracy solely trained on ImageNet-1K)</p></p></li> -->
                  
          <!-- <li><b> Can Shape Structure Features Improve Model Robustness? </b> <p class='content'>Mingjie Sun*, Zichao Li*,<strong>Chaowei Xiao</strong>*, Haonan Qiu, Bhavya Kailkhura, MingyanLiu, Bo Li. <p>ICCV 2021</p></p></li> -->
           
           <li><b> [Security] Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion based Perception in Autonomous Driving Under Physical-World Attacks.</b> <p class='content'>Yulong Cao*, Ningfei Wang*,<strong>Chaowei Xiao</strong>*, Dawei Yang*, Jin Fang, RuigangYang, Qi Alfred Chen, Mingyan Liu, Bo Li. <p>IEEE Symposium on Security and Privacy (Oakland) 2021</p></p></li>
           <!-- Yulong Cao, Ningfei Wang,<strong>Chaowei Xiao</strong>, Dawei Yang, Jin Fang, RuigangYang, Qi Alfred Chen, Mingyan Liu, Bo Li.  (IEEE Symposium on Security and Privacy (Oakland), 2021 -->
           <!-- <li><b>  Behavior Privacy Perserving in RF Sensing.</b> <p class='content'>Jianwie Liu,Chaowei Xiao, Kaiyan Cui, Jinsong Han, Xian Xu, Kui Ren. <p> IEEE Transcations on Dependable and Secure Computing. <a href="pdf/TDSC.pdf">[pdf]</a></p></p></li> -->
           <!-- </ul> -->
           <!-- <h5>2020</h5> -->
           <!-- <ul> -->
           <!-- <li><b>[Security] SemanticAdv: Generating Adversarial Examples via Attribute-conditional Image Editing</b><p class='content'> Haonan Qiu*, <strong>Chaowei Xiao*</strong>, Lei Yang*, Xinchen Yan, Honglak Lee,  Bo Li.  <p>ECCV 2020</p></p> -->
     
            <!-- <li><b>[Security] Towards Stable and Efficient Training of Verifiably Robust Neural Networks</b><p class='content'> Huan Zhang, Hongge Chen, <strong>Chaowei Xiao</strong>, Sven Gowal, Robert Stanforth, Bo Li, Duane Boning, Cho-Jui Hsieh.  <p>ICLR 2020.</p></p>
            </li> -->
            <!-- </ul> -->
            <!-- <h5>2019</h5> -->
            <!-- <ul> -->
      <!-- <li><b>AdvIT: Adversarial Frames Identifier Based on Temporal Consistency In Videos</b><p class='content'> <strong>Chaowei Xiao</strong>, Ruizhi Deng, Bo Li, Taesung Lee, Jinfeng Yi, Ian Molloy, Mingyan Liu, Dawn Song</p>
            <p>In International Conference on Computer Vision (ICCV) 2019.</p>
             </li> -->


    <!-- <li><b>Performing Co-Membership Attack Against Deep Generative Model</b><p class='content'> Kin Sum Liu, <strong> Chaowie Xiao </strong>, Bo Li, Jie Gao</p> <p>In IEEE International Conference on Data Mining (ICDM) 2019</p></li> -->
    <!-- <li><b>Improving Robustness of ML Classifiers against Realizable Evasion Attacks Using Conserved Features</b><p class='content'> Liang Tong, Bo Li, Chen Hajaj, <strong>Chaowei Xiao</strong>, Ning Zhang, Yevgeniy Vorobeychik.</p> -->
    <!-- <p>In USENIX Security 2019. </p> -->
    <!-- </li> -->
  
  <!-- </ul> -->
  <!-- <h5>2018</h5> -->
  <!-- <ul> -->
  <!-- <li><b>Characterizing Adversarial Examples Based on Spatial Consistency Information for Semantic Segmentation</b>
    <p class="content"><strong>Chaowei Xiao</strong>, Duizhi Deng, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, <a href="http://www.yf.io/">Fisher Yu</a>, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p class="">In European Conference on Computer Vision (ECCV), 2018 <a href="pdf/ECCV_CR_1682.pdf">[pdf]</a><a href="pdf/1682_supp.pdf">[supplementary material]</a>

    </p> -->
  </li>
  <li><b>[Security] Spatially Transformed Adversarial Examples</b>
    <p class="content"><strong>Chaowei Xiao*</strong>, <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu*</a>, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, Warren He, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p class="">In International Conference on Learning Representations (ICLR), 2018 <a href="https://arxiv.org/abs/1801.02612">[pdf]</a>

    </p>
  </li>
  <li><b>[Security] Generating Adversarial Examples with Adversarial Networks</b>
    <p class="content"><strong>Chaowei Xiao</strong>, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu</a>, Warren He, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p>In International Joint Conference on Artificial Intelligence (IJCAI), 2018. <a href="https://arxiv.org/abs/1801.02610">[pdf]</a>

  </p>
  </li>
  <!-- <li><b>From Behavior Similarity to Symptom Similarity: Using Community Detection for Early Discovery of Software Exploits</b>
    <p class="content"><strong>Chaowei Xiao</strong>, Armin Sarabi,<a href="http://www-personal.umich.edu/~youngliu/">Yang Liu </a>, <a href="http://boli.cs.illinois.edu">Bo Li</a>, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="http://legacydirs.umiacs.umd.edu/~tdumitra/">Tudor Dumitras</a></p>
    <p>In USENIX Security Symposium (USENIX Security), 2018 <a href='pdf/sec18-final415.pdf'>[pdf]</a>
    </p>
  </li> -->
 <li><b>[Security] Robust Physical-World Attacks on Machine Learning Models</b>
    <p class="content"> Kevin Eykholt*, <a href="https://ivanevtimov.eu/">Ivan Evtimov*</a>, <a>Earlence Fernandes</a>, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, <a href="https://amir.rahmati.com/">Amir Rahmati</a>, <strong>Chaowei Xiao</strong>,  <a href="http://web.eecs.umich.edu/~aprakash/">Atul Prakash</a>,  <a href="https://homes.cs.washington.edu/~yoshi/">Tadayoshi Kohno</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018 <a href="https://arxiv.org/abs/1707.08945">[pdf]</a>

  </p>
  </li>
  <!-- <li><b>Patch Me If You Can: A Study on the effects of Individual User Behavior on the End-Host Vulnerability State</b>
    <p class="content">Armin Sarabi, Ziyun Zhu, <strong>Chaowei Xiao</strong>, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="http://legacydirs.umiacs.umd.edu/~tdumitra/">Tudor Dumitras</a></p>
    <p>In Passive and Active Measurement conference (PAM), 2017 <a href="http://web.eecs.umich.edu/~mingyan/pub/PAM17_102-Sarabi.pdf">[pdf]</a>

    </p>
  </li> -->
<!-- </ul>
<h5>Before 2018</h5>
<ul>
  <li><b>Static Power of Mobile Devices: Self-updating Radio Maps for Wireless Indoor Localization</b>
    <p class="content"><a href="http://cswu.me/">Chenshu Wu</a>, <a href="http://www.tsinghua.edu.cn/publish/soften/3131/2013/20130711152929220429684/20130711152929220429684_.html">Zheng Yang</a>, <strong>Chaowei Xiao</strong>, Chaofan Yang, <a href="http://www.cse.msu.edu/~liuyunha/">Yunhao Liu</a> and <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a>
    <p>In IEEE International Conference on Computer Communications (INFOCOM), 2015
    </p> 
  </li>
  <li><b>Tagoram: Real-time Tracking of Mobile RFID Tags to High Precision Using COTS Devices.</b>
    <p class="content"><a href="http://www4.comp.polyu.edu.hk/~csyanglei/">Lei Yang</a>, Yekui Chen, <a href="http://www.cs.iit.edu/~xli/">Xiangyang Li</a>, <strong>Chaowei Xiao</strong>, <a href="https://www.ntu.edu.sg/home/limo/">Mo Li</a> and <a href="http://www.cse.msu.edu/~liuyunha/">Yunhao Liu</a> </p>
    <p>In International Conference on Mobile Computing and Networking (MobiCom), 2014. <span style="color:#FF3333;"">Best Paper Award</span> -->

    </p>
  </li>
 <!--  <li><b>Automatic Radio Map Adaptation for Indoor Localization using Smartphones</b>
        <p class="content"><a href="http://cswu.me/">Chenshu Wu</a>, <a href="http://www.tsinghua.edu.cn/publish/soften/3131/2013/20130711152929220429684/20130711152929220429684_.html">Zheng Yang</a> and <strong><strong>Chaowei Xiao</strong></strong>,</a>
    <p>In IEEE Transactions on Mobile Computing (TMC) 2017
    </p>
  </li>
 -->

</ul>


          
        <!-- </div> -->
      </div>

   <div class=" my-4 text-left">      
<!-- <div class="card-body"> -->
          <h4 id="pub">Full Publications </h4>
           <p>(* represents equal contribution) </p>
     <h5>2025</h5>
    <ul>
<li> <b> Preference Poisoning Attacks on Reward Model Learning
</b> <p class='content'>  Junlin Wu, Jiongxiao Wang, Chaowei Xiao, Chenguang Wang, Ning Zhang, Yevgeniy Vorobeychik.<p>IEEE S&P 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
      
      <li> <b>AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs
</b> <p class='content'> Xiaogeng Liu, Peiran Li, G. Edward Suh, Yevgeniy Vorobeychik, Zhuoqing Mao, Somesh Jha, Patrick McDaniel, Huan Sun, Bo Li, Chaowei Xiao. <p>ICLR 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

     <li> <b> Can Watermarks be Used to Detect LLM IP Infringement For Free?
</b> <p class='content'> Zhengyue Zhao, Xiaogeng Liu, Somesh Jha, Patrick McDaniel, Bo Li, Chaowei Xiao. <p>ICLR 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
      
      <li> <b>Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset
</b> <p class='content'> Yingzi Ma, Jiongxiao Wang, Fei Wang, Siyuan Ma, Jiazhao Li, Jinsheng Pan, Xiujun Li, Furong Huang, Lichao Sun, Bo Li, Yejin Choi, Muhao Chen, Chaowei Xiao. <p>ICLR 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

 <li> <b>CVE-Bench: Benchmarking LLM-based Software Engineering Agentâ€™s Ability to Repair Real-World CVE Vulnerabilities
</b> <p class='content'> Peiran Wang, Xiaogeng Liu, Chaowei Xiao. <p>NAACL 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

      <li> <b>RePD: Defending Jailbreak Attack through a Retrieval-based Prompt Decomposition Process
</b> <p class='content'> Peiran Wang, Xiaogeng Liu, Chaowei Xiao. <p>NAACL 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

    <li> <b>Test-time Backdoor Mitigation for Black-Box Large Language Models with Defensive Demonstrations
</b> <p class='content'> Wenjie Jacky Mo, Jiashu Xu, Qin Liu, Jiongxiao Wang, Jun Yan, Hadi Askari, Chaowei Xiao, Muhao Chen. <p>NAACL 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>


      
      
      <li> <b> T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching
</b> <p class='content'> Zizheng Pan, Bohan Zhuang, De-An Huang, Weili Nie, Zhiding Yu, Chaowei Xiao, Jianfei Cai, Anima Anandkumar. <p>ICLR 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>


      
      <li> <b> LeanAgent: Lifelong Learning for Formal Theorem Proving. 
</b> <p class='content'> Adarsh Kumarappan, Mo Tiwari, Peiyang Song, Robert Joseph George, Chaowei Xiao, Anima Anandkumar. <p>ICLR 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>


      
      <li> <b> MuirBench: A Comprehensive Benchmark for Robust Multi-image Understanding
</b> <p class='content'> Fei Wang, Xingyu Fu, James Y. Huang, Zekun Li, Qin Liu, Xiaogeng Liu, Mingyu Derek Ma, Nan Xu, Wenxuan Zhou, Kai Zhang, Tianyi Lorena Yan, Wenjie Jacky Mo, Hsiang-Hui Liu, Pan Lu, Chunyuan Li, Chaowei Xiao, Kai-Wei Chang, Dan Roth, Sheng Zhang, Hoifung Poon, Muhao Chen. <p>ICLR 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

      <li> <b> DataGen: Unified Synthetic Dataset Generation via Large Language Models
</b> <p class='content'> Yue Huang, Siyuan Wu, Chujie Gao, Dongping Chen, Qihui Zhang, Yao Wan, Tianyi Zhou, Chaowei Xiao, Jianfeng Gao, Xiangliang Zhang, Lichao Sun. <p>ICLR 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

 <li> <b> EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage
</b> <p class='content'> Zeyi Liao, Lingbo Mo, Chejian Xu, Mintong Kang, Jiawei Zhang, Chaowei Xiao, Yuan Tian, Bo Li, Huan Sun. <p>ICLR 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
      
      
    <li> <b> Robust Representation Consistency Model via Contrastive Denoising
</b> <p class='content'> Jiachen Lei, Julius Berner, Jiongxiao Wang, Zhongzhu Chen, Chaowei Xiao, Zhongjie Ba, Kui Ren, Jun Zhu, Anima Anandkumar.<p>ICLR 2025. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>


      
    
    
    </ul> 
     <h5> 2024</h5>
         <ul>


           

           <li> <b> BackAlign: Mitigating Fine-tuning based Jailbreak Attack with Backdoor Enhanced Safety Alignment
</b> <p class='content'> Jiongxiao Wang, Jiazhao Li, Yiquan Li, Xiangyu Qi, Junjie Hu, Yixuan Li, Patrick McDaniel, Muhao Chen, Bo Li, Chaowei Xiao<p>NeurIPS 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

           <li> <b> HaloScope: Harnessing Unlabeled LLM Generations for Hallucination Detection
 
</b> <p class='content'>  Xuefeng Du, Chaowei Xiao, Yixuan Li.<p>NeurIPS 2024 (Spotlight). <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

           <li> <b> Consistency Purification: Effective and Efficient Diffusion Purification towards Certified Robustness
</b> <p class='content'>  Yiquan Li, Zhongzhu Chen, Kunjin, Jiongxiao Wang, Bo Li, Chaowei Xiao.<p>NeurIPS 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

 <li> <b>AgentPoison: Red-teaming LLM Agents via Memory or Knowledge Base Backdoor Poisoning
</b> <p class='content'> Zhaorun Chen, Zhen Xiang, Chaowei Xiao, Dawn Song, Bo Li. .<p>NeurIPS 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>


           
<li><b> Jailbreakv-28k: A benchmark for assessing the robustness of multimodal large language models against jailbreak attacks
</b> <p class='content'>Weidi Luo, Siyuan Ma, Xiaogeng Liu, Xiaoyu Guo, Chaowei Xiao.<p>COLM 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>


           <li><b> Dolphins: Multi-
modal Language Model for Driving. </b> <p class='content'>Yingzi Ma, Yulong Cao, Jiachen Sun, Marco Pavone, Chaowei Xiao.<p>ECCV 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
           <li><b> AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting.</b> <p class='content'>Yu Wang, Xiaogeng Liu, Yu Li, Muhao Chen, Chaowei Xiao.<p>ECCV 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

<li><b>  RealGen: Retrieval Augmented Generation for Controllable Tra c Scenarios.</b> <p class='content'>Wenhao Ding, Yulong Cao, Ding Zhao, Chaowei Xiao, Marco Pavone.<p>ECCV 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>


<li><b> Leveraging Hierarchical Feature Sharing for E cient Dataset Condensation.</b> <p class='content'>Haizhong Zheng, Jiachen Sun, Shutong Wu,Bhavya Kaikhura, Zhuoqing Mao, Chaowei Xiao, Atul Prakash.<p>ECCV 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

<li><b>  On the exploitability of reinforcement learning with human feedback for large language models.</b> <p class='content'> Jiongxiao Wang, Junlin Wu, Muhao Chen, Yevgeniy Vorobeychik, Chaowei Xiao.<p>ACL 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

            <li><b> Position Paper: TrustLLM: Trustworthiness in Large Language Models.</b> <p class='content'> TrustLLM Team.<p>ICML 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
            <li><b> PerAda: Parameter-E cient Federated Learning Personalization with Generalization Guarantees.</b> <p class='content'>  Chulin Xie, De-An Huang, Wenda Chu, Daguang Xu, Chaowei Xiao*, Bo Li*, and Anima Anandkumar*. <p>CVPR 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

            <li><b>  Do Not Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models. </b> <p class='content'>   Zhiyuan Yu, Xiaogeng Liu, Shuning Liang, Zach Cameron,Chaowei Xiao, Ning Zhang. <p>USENIX Security 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
            <li><b>  Reinforcement Learning with Human Feedback for Realistic Tra c Simulation.</b> <p class='content'>   Yulong Cao, Boris Ivanovic, Chaowei Xiao, Marco Pavone.  <p>ICRA  2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

     
           <li><b> AutoDan: Generating stealthy jailbreak prompts on aligned large language models. </b> <p class='content'>Xiaogeng Liu, Nan Xu, Muhao Chen, Chaowei Xiao<p>ICLR 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>


     <li><b> ChatGPT-powered Conversational Drug Editing Using Retrieval and Domain Feedback   </b> <p class='content'>Shengchao Liu, Jiongxiao Wang, Yijin Yang, Chengpeng Wang, Ling Liu, Hongyu Guo, Chaowei Xiao <p>ICLR 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

     <li><b> CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception.       </b> <p class='content'>Jiachen Sun, Haizhong Zheng, Qingzhao Zhang, Atul Prakash, Z. Morley Mao, and Chaowei Xiao <p>ICLR 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

     <li><b>ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger.    </b> <p class='content'>Jiazhao Li, Yijin Yang, Zhuofeng Wu, V.G.Vinod Vydiswaran, Chaowei Xiao.<p>NAACL 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

           <li><b> Instructional Fingerprinting of Large Language Models.       </b> <p class='content'>Jiashu Xu, Fei Wang, Mingyu Derek Ma, Pang Wei Koh, Chaowei Xiao, Muhao Chen.<p>NAACL 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
           <li><b> Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models.  </b> <p class='content'>Jiashu Xu, Fei Wang, Mingyu Derek Ma, Pang Wei Koh, Chaowei Xiao, Muhao Chen.<p>NAACL 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>


     <li><b>From Shortcuts to Triggers: Backdoor Defense with Denoised PoE.  </b> <p class='content'>Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen. <p>NAACL 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

     <li><b> Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking.       </b> <p class='content'>Nan Xu, Fei Wang, Ben Zhou, Bangzheng Li, Chaowei Xiao, Muhao Chen.<p>NAACL 2024 (findings). <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
           

           
     <li><b>Prismer: A Vision-Language Model with Multi-Task Experts </b> <p class='content'>Shikun Liu, Linxi Fan, Edward Johns, Zhiding Yu, Chaowei Xiao, Anima Anandkumar. <p>TLMR 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

           
           <li><b>Voyager: An open-ended embodied agent with large language models </b> <p class='content'>Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, Anima Anandkumar<p>TLMR 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>



      <li><b> Multi-modal molecule structureâ€“text model for text-based retrieval and editing    </b> <p class='content'>Shengchao Liu, Weili Nie, Chengpeng Wang, Jiarui Lu, Zhuoran Qiao, Ling Liu, Jian Tang*,  Chaowei Xiao*, Animashree Anandkumar*.  <p>Natural Machine Intelligence. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>



     <li><b> Differentially Private Video Activity Recognition. </b> <p class='content'>Zelun Luo, Yuliang Zou, Yijin Yang, Zane Durante, De-An Huang, Zhiding Yu, 
, Chaowei Xiao, Li Fei-Fei, Animashree Anandkumar. <p>WACV 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>


     <li><b> Semantic Adversarial Attacks via Diffusion Models. </b> <p class='content'>Chenan Wang, Jinhao Duan, Chaowei Xiao, Edward Kim, Matthew Stamm, Kaidi Xu. <p>BMCV 2024. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

           
         </ul>
    <h5> 2023</h5>
         <ul>


   
      <li><b> Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study         </b> <p class='content'> Boxin Wang, Wei Ping, Peng Xu, Lawrence McAfee, Zihan Liu, Mohammad Shoeybi, Yi Dong, Oleksii Kuchaiev, Bo Li, Chaowei Xiao, Anima Anandkumar, Bryan Catanzaro <p>EMNLP 2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
          <li><b> Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning        </b> <p class='content'> Zhuolin Yang, Wei Ping, Zihan Liu, Vijay Anand Korthikanti, Weili Nie, De-An Huang, Linxi Fan, Zhiding Yu, Shiyi Lan, Bo Li, Mohammad Shoeybi, Ming-Yu Liu, Yuke Zhu, Bryan Catanzaro, <strong>Chaowei Xiao*</strong>, Anima Anandkumar* <p>EMNLP   2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
          <li><b> HiCL: Hierarchical Contrastive Learning of Unsupervised Sentence Embeddings        </b> <p class='content'> Zhuofeng Wu, <strong>Chaowei Xiao</strong>, V.G.Vinod Vydiswaran<p>EMNLP   2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
        
          
           <li><b> On the Exploitability of Instruction Tuning      </b> <p class='content'> Manli Shu, Jiongxiao Wang, Chen Zhu, Jonas Geiping, <strong>Chaowei Xiao*</strong>, Tom Goldstein* <p>NeurIPS   2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
      <li><b>[LLM Safety]Defending against Insertion-based Textual Backdoor Attacks via Attribution. </b><p class='content'>Jiazhao Li, Zhuofeng Wu, Wei Ping, Chaowei Xiao, V.G. Vinod Vydiswaran.</p><p> ACL 2023</p> </li>
           <li><b> CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models          </b> <p class='content'> Zhiyuan Yu, Yuhao Wu, Ning Zhang, Chenguang Wang, Yevgeniy Vorobeychik, <strong>Chaowei Xiao</strong><p>ICML   2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
          <li><b> A Critical Revisit of Adversarial Robustness in 3D Point Cloud Recognition with Diffusion-Driven Purification. </b> <p class='content'>  Jiachen Sun, Jiongxiao Wang, Weili Nie, Zhiding Yu, Zhuoqing Mao, <strong>Chaowei Xiao</strong><p>ICML  2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

          
          <li><b> VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion. </b> <p class='content'>  Yiming Li, Zhiding Yu, Chris Choy, <strong>Chaowei Xiao</strong>, Jose M. Alvarez, Sanja Fidler, Chen Feng, Anima Anandkumar <p>CVPR 2023 (Highlight). <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
          <li><b>  Expunging Clean-label Invisible Poisons via Pre-trained Diffusion Models. </b> <p class='content'> Xiaogeng Liu, Minghui Li, Haoyu Wang, Shengshan Hu, Dengpan Ye, Hai Jin, Libing Wu,<strong>Chaowei Xiao</strong>. <p>CVPR 2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
 
          <li><b>  DiffSmooth: Certifiably Robust Learning via Diffusion Models and Local Smoothing. </b> <p class='content'>  Jiawei Zhang, , Zhongzhu Chen, Huan Zhang, <strong>Chaowei Xiao</strong>,  Bo Li.  <p>USENIX Security  2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
 
 <li><b>  DensePure: Understanding Diffusion Models towards Adversarial Robustness. </b> <p class='content'>  <strong>Chaowei Xiao</strong>*, Zhongzhu Chen*, Kun Jin*, Jiongxiao Wang*, Weili Nie, Mingyan Liu, Anima Anandkumar, Bo Li, Dawn Song  <p>ICLR  2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
  <li><b>  Defending against Adversarial Audio via Diffusion Model </b> <p class='content'> Shutong Wu, Jiongxiao Wang, Wei Ping, Weili Nie,<strong>Chaowei Xiao</strong>  <p>ICLR 2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
        <li><b>  Retrieval-based Controllable Molecule Generation </b> <p class='content'> Zichao Wang, Weili Nie, Zhuoran Qiao, <strong> Chaowei Xiao </strong>, Richard Baraniuk, Anima Anandkumar <p>ICLR 2023 (spotlight). <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
         <li><b>  Semantically Meaningful Adversarial Audio Attack</b> <p class='content'> Zhiyuan Yu, Yuanhaur Chang, Ning Zhang, <strong>Chaowei Xiao</strong>  <p>USENIX Security 2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
          <li><b>  GenSLMs: Genome-scale language
models reveal SARS-CoV-2 evolutionary dynamics. </b> <p class='content'> Maxim Zvyagin*, Alexander Brace*, Kyle Hippe*, Yuntian Deng*, Bin Zhang, Cindy Orozco Bohorquez, Austin Clyde, Bharat Kale, Danilo Perez-Rivera, Heng Ma, Carla M. Mann, Michael Irvin,
J. Gregory Pauloski, Logan Ward, Valerie Hayot, Murali Emani, Sam Foreman, Zhen Xie, Diangen Lin, Maulik Shukla, Weili Nie, Josh Romero, Christian Dallago, Arash Vahdat, <strong>Chaowei Xiao</strong>,
Thomas Gibbs, Ian Foster, James J. Davis, Michael E. Papka, Thomas Brettin, Rick Stevens, Anima Anandkumar, Venkatram Vishwanath, Arvind Ramanathan.  <p>ACM Gordon Bell Special Covid Prize<a href="">[pdf]</a> <a href="">[code]</a></p></p></li>

</ul>

           <h5> 2022</h5>
         <ul>
         
          <li><b> Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models</b> <p class='content'>Manli Shu, Weili Nie, De-An Huang, Zhiding Yu, Tom Goldstein, Anima Anandkumar,  <strong>Chaowei Xiao</strong>  <p>NeurIPS 2022. <a href="https://arxiv.org/abs/2209.07511">[pdf]</a> <a href="">[code]</a></p></p></li>
          
          <li><b>  Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models</b> <p class='content'>Boxin Wang, Wei Ping, <strong>Chaowei Xiao</strong>, Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Bo Li, Anima Anandkumar, Bryan Catanzaro. <p>NeurIPS 2022<a href="https://arxiv.org/abs/2202.04173">[pdf]</a> <a href="">[code]</a></p></p></li>
          
          <li><b>  Robust Trajectory Prediction against Adversarial Attacks</b> <p class='content'>Yulong Cao, Danfei Xu, Xinshuo Weng, Z. Morley Mao, Anima Anandkuma, <strong>Chaowei Xiao</strong>, Marco Pavone <p>CORL 2022 (Oral)<a href="https://arxiv.org/pdf/2208.00094.pdf">[pdf]</a> <a href="">[code]</a></p></p></li>
          
          <li><b>  Diffusion Models for Adversarial Purification</b> <p class='content'>Weili Nie, Brandon Guo, Yujia Huang,<strong>Chaowei Xiao</strong>, Arash Vahdat, Anima Anandkumar. <p>ICML 2022<a href="https://arxiv.org/abs/2205.07460">[pdf]</a> <a href="https://github.com/NVlabs/DiffPure">[code]</a></p></p></li>
          
          <li><b> Understanding the robustness in vision transformers.</b> <p class='content'>Daquan Zhou, Zhiding Yu, Enze Xie,<strong>Chaowei Xiao</strong>, Anima Anandkumar, Jiashi Feng, Jose M Alvarez.<p>ICML 2022<a href="https://arxiv.org/abs/2204.12451">[pdf]</a> <a href="https://github.com/NVlabs/FAN">[code]</a></p></p></li>
          

          <li><b> AdvDO: Realistic Adversarial Attacks for
            Trajectory Prediction</b> <p class='content'>Yulong Cao,<strong>Chaowei Xiao</strong>, Anima Anandkumar, Danfei Xu,
              Marco Pavone.<p>ECCV 2022<a href="">[pdf]</a> <a href="">[code]</a></p></p></li>


          <li><b> SecretGen: Privacy Recovery on Pre-trained Models</b> <p class='content'>Zhuowen Yuan, Fan Wu, Yunhui Long,<strong>Chaowei Xiao</strong>, Bo Li<p>ECCV 2022<a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
          
         
          <li><b> Taxonomy of Machine Learning Safety: A Survey and Primer</b> <p class='content'>Sina Mohseni, Zhiding Yu, <strong>Chaowei Xiao</strong> Jay Yadawa, Haotao Wang and Zhangyang Wang<p>ACM Computing Survey 2022<a href="https://arxiv.org/abs/2106.04823">[pdf]</a></p></p></li>



          <li><b> RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning</b><p class='content'> Xiaojian Ma, Weili Nie, Zhiding Yu, Huaizu Jiang,<strong>Chaowei Xiao</strong>, Yuke Zhu, Song-Chun Zhu, Anima Anandkumar <p>ICLR 2022<a href="https://web.cs.ucla.edu/~xm/file/relvit_iclr22.pdf">[pdf]</a> <a href="https://github.com/NVlabs/RelViT">[code]</a></p></p></li>
          
          <li><b> Characterizing Attacks on Deep Reinforcement Learning. </b> <p class='content'>Xinlei Pan*,<strong>Chaowei Xiao</strong>*, Warren He, Shuang Yang, Peng Jian, Mingjie Sun, Mingyan Liu, Bo Li, Dawn Song.  <p>AAMAS 2022 <a href="pdf/aamas_2022.pdf">[pdf]</a></p></p></li>

            </ul>
          <h5>2021</h5>
          <ul>
          <li><b> Adversarially Robust 3D Point Cloud Recognition Using Self-Supervisions. </b> <p class='content'>Jiachen Sun, Yulong Cao, Christopher Choy, Zhiding Yu, Anima Anandkumar, Z. Morley Mao, <strong>Chaowei Xiao</strong>. <p>NeurIPS 2021</p></p></li>

          <li><b> AugMax: Adversarial Composition of RandomAugmentations for Robust Training. </b> <p class='content'>Haotao Wang,<strong>Chaowei Xiao</strong>, Jean Kossaifi, Zhiding Yu, Animashree Anandkumar,  Zhangyang Wang.  <p>NeurIPS 2021</p></p></li>
         
          <li><b> Efficient Transformers for Language and Vision. </b> <p class='content'>Chen Zhu, Wei Ping,<strong>Chaowei Xiao</strong>, Mohammad Shoeybi, Tom Goldstein, Anima Anandkumar, Bryan Catanzaro. <p>NeurIPS 2021 (84.1% Top-1 accuracy solely trained on ImageNet-1K)</p></p></li>
                  
          <li><b> Can Shape Structure Features Improve Model Robustness? </b> <p class='content'>Mingjie Sun*, Zichao Li*,<strong>Chaowei Xiao</strong>*, Haonan Qiu, Bhavya Kailkhura, MingyanLiu, Bo Li. <p>ICCV 2021</p></p></li>
           
           <li><b> Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion based Perception in Autonomous Driving Under Physical-World Attacks.</b> <p class='content'>Yulong Cao*, Ningfei Wang*,<strong>Chaowei Xiao</strong>*, Dawei Yang*, Jin Fang, RuigangYang, Qi Alfred Chen, Mingyan Liu, Bo Li. <p>IEEE Symposium on Security and Privacy (Oakland) 2021</p></p></li>
           <!-- Yulong Cao, Ningfei Wang,<strong>Chaowei Xiao</strong>, Dawei Yang, Jin Fang, RuigangYang, Qi Alfred Chen, Mingyan Liu, Bo Li.  (IEEE Symposium on Security and Privacy (Oakland), 2021 -->
           <li><b> Application-Driven Privacy-Preserving Data Publishing with Correlated Attributes. </b> <p class='content'>Aria Rezaei,<strong>Chaowei Xiao</strong>, Jie Gao, Bo Li, Sirajum Munir. <p>Embedded Wireless Systems and Networks (EWSN 2021)<span style="color:#FF3333;"">Best Paper Award</span></p></p></li>
           <li><b>  Behavior Privacy Perserving in RF Sensing.</b> <p class='content'>Jianwie Liu,Chaowei Xiao, Kaiyan Cui, Jinsong Han, Xian Xu, Kui Ren. <p> IEEE Transcations on Dependable and Secure Computing. <a href="pdf/TDSC.pdf">[pdf]</a></p></p></li>
           </ul>
           <h5>2020</h5>
           <ul>
           <li><b>SemanticAdv: Generating Adversarial Examples via Attribute-conditional Image Editing</b><p class='content'> Haonan Qiu*, <strong>Chaowei Xiao*</strong>, Lei Yang*, Xinchen Yan, Honglak Lee,  Bo Li.  <p>ECCV 2020</p></p>
          </li>
          <li><b>Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations</b><p class='content'> Huan Zhang*, Hongge Chen*, <strong>Chaowei Xiao</strong>,  Bo Li, Mingyan Liu, Duane Boning, Cho-Jui Hsieh.  <p>NeurIPS 2020 (Spotlight).</p></p>
          </li>

            <li><b>Towards Stable and Efficient Training of Verifiably Robust Neural Networks</b><p class='content'> Huan Zhang, Hongge Chen, <strong>Chaowei Xiao</strong>, Sven Gowal, Robert Stanforth, Bo Li, Duane Boning, Cho-Jui Hsieh.  <p>ICLR 2020.</p></p>
            </li>
            </ul>
            <h5>2019</h5>
            <ul>
      <li><b>AdvIT: Adversarial Frames Identifier Based on Temporal Consistency In Videos</b><p class='content'> <strong>Chaowei Xiao</strong>, Ruizhi Deng, Bo Li, Taesung Lee, Jinfeng Yi, Ian Molloy, Mingyan Liu, Dawn Song</p>
            <p>In International Conference on Computer Vision (ICCV) 2019.</p>
             </li>
     <li><b>MeshAdv: Adversarial Meshes for Visual Recognition</b><p class='content'> <strong>Chaowei Xiao*</strong>, Dawei Yang*, Bo Li, Jia Deng, Mingyan Liu</p>
    <p>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2019. (Oral presentation) <a href="https://arxiv.org/abs/1810.05206">[pdf]</a></p>
    </li>
    <li><b>Performing Co-Membership Attack Against Deep Generative Model</b><p class='content'> Kin Sum Liu, <strong> Chaowie Xiao </strong>, Bo Li, Jie Gao</p> <p>In IEEE International Conference on Data Mining (ICDM) 2019</p></li>
    <li><b>Improving Robustness of ML Classifiers against Realizable Evasion Attacks Using Conserved Features</b><p class='content'> Liang Tong, Bo Li, Chen Hajaj, <strong>Chaowei Xiao</strong>, Ning Zhang, Yevgeniy Vorobeychik.</p>
    <p>In USENIX Security 2019. </p>
    </li>
     <li><b>Adversarial Sensor Attack on LIDAR-based Perception in Autonomous Driving</b><p class='content'> Yulong Cao, <strong>Chaowei Xiao</strong>, Benjamin Cyr, Yimeng Zhou, Won Park, Sara Rampazzi, Qi Alfred Chen, Kevin Fu, Z. Morely Map </p>
    <p>In the 26th ACM Conference on Computer and Communications Security (CCS'19) <a href="https://arxiv.org/abs/1907.05418">[pdf]</a></p>
    </li>
  </ul>
  <h5>2018</h5>
  <ul>
  <li><b>Characterizing Adversarial Examples Based on Spatial Consistency Information for Semantic Segmentation</b>
    <p class="content"><strong>Chaowei Xiao</strong>, Duizhi Deng, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, <a href="http://www.yf.io/">Fisher Yu</a>, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p class="">In European Conference on Computer Vision (ECCV), 2018 <a href="pdf/ECCV_CR_1682.pdf">[pdf]</a><a href="pdf/1682_supp.pdf">[supplementary material]</a>

    </p>
  </li>
  <li><b>Spatially Transformed Adversarial Examples</b>
    <p class="content"><strong>Chaowei Xiao*</strong>, <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu*</a>, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, Warren He, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p class="">In International Conference on Learning Representations (ICLR), 2018 <a href="https://arxiv.org/abs/1801.02612">[pdf]</a>

    </p>
  </li>
  <li><b>Generating Adversarial Examples with Adversarial Networks</b>
    <p class="content"><strong>Chaowei Xiao</strong>, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu</a>, Warren He, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p>In International Joint Conference on Artificial Intelligence (IJCAI), 2018. <a href="https://arxiv.org/abs/1801.02610">[pdf]</a>

  </p>
  </li>
  <li><b>From Behavior Similarity to Symptom Similarity: Using Community Detection for Early Discovery of Software Exploits</b>
    <p class="content"><strong>Chaowei Xiao</strong>, Armin Sarabi,<a href="http://www-personal.umich.edu/~youngliu/">Yang Liu </a>, <a href="http://boli.cs.illinois.edu">Bo Li</a>, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="http://legacydirs.umiacs.umd.edu/~tdumitra/">Tudor Dumitras</a></p>
    <p>In USENIX Security Symposium (USENIX Security), 2018 <a href='pdf/sec18-final415.pdf'>[pdf]</a>
    </p>
  </li>
 <li><b>Robust Physical-World Attacks on Machine Learning Models</b>
    <p class="content"> Kevin Eykholt*, <a href="https://ivanevtimov.eu/">Ivan Evtimov*</a>, <a>Earlence Fernandes</a>, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, <a href="https://amir.rahmati.com/">Amir Rahmati</a>, <strong>Chaowei Xiao</strong>,  <a href="http://web.eecs.umich.edu/~aprakash/">Atul Prakash</a>,  <a href="https://homes.cs.washington.edu/~yoshi/">Tadayoshi Kohno</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018 <a href="https://arxiv.org/abs/1707.08945">[pdf]</a>

  </p>
  </li>
  <!-- <li><b>Patch Me If You Can: A Study on the effects of Individual User Behavior on the End-Host Vulnerability State</b>
    <p class="content">Armin Sarabi, Ziyun Zhu, <strong>Chaowei Xiao</strong>, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="http://legacydirs.umiacs.umd.edu/~tdumitra/">Tudor Dumitras</a></p>
    <p>In Passive and Active Measurement conference (PAM), 2017 <a href="http://web.eecs.umich.edu/~mingyan/pub/PAM17_102-Sarabi.pdf">[pdf]</a>

    </p>
  </li> -->
</ul>
<h5>Before 2018</h5>
<ul>
  <li><b>Static Power of Mobile Devices: Self-updating Radio Maps for Wireless Indoor Localization</b>
    <p class="content"><a href="http://cswu.me/">Chenshu Wu</a>, <a href="http://www.tsinghua.edu.cn/publish/soften/3131/2013/20130711152929220429684/20130711152929220429684_.html">Zheng Yang</a>, <strong>Chaowei Xiao</strong>, Chaofan Yang, <a href="http://www.cse.msu.edu/~liuyunha/">Yunhao Liu</a> and <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a>
    <p>In IEEE International Conference on Computer Communications (INFOCOM), 2015
    </p> 
  </li>
  <li><b>Tagoram: Real-time Tracking of Mobile RFID Tags to High Precision Using COTS Devices.</b>
    <p class="content"><a href="http://www4.comp.polyu.edu.hk/~csyanglei/">Lei Yang</a>, Yekui Chen, <a href="http://www.cs.iit.edu/~xli/">Xiangyang Li</a>, <strong>Chaowei Xiao</strong>, <a href="https://www.ntu.edu.sg/home/limo/">Mo Li</a> and <a href="http://www.cse.msu.edu/~liuyunha/">Yunhao Liu</a> </p>
    <p>In International Conference on Mobile Computing and Networking (MobiCom), 2014. <span style="color:#FF3333;"">Best Paper Award</span>

    </p>
  </li>
 <!--  <li><b>Automatic Radio Map Adaptation for Indoor Localization using Smartphones</b>
        <p class="content"><a href="http://cswu.me/">Chenshu Wu</a>, <a href="http://www.tsinghua.edu.cn/publish/soften/3131/2013/20130711152929220429684/20130711152929220429684_.html">Zheng Yang</a> and <strong><strong>Chaowei Xiao</strong></strong>,</a>
    <p>In IEEE Transactions on Mobile Computing (TMC) 2017
    </p>
  </li>
 -->

</ul>


          
        <!-- </div> -->
      </div>
      
      <div class="my-4 text-left">
      <a href="https://clustrmaps.com/site/1bjs5"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=ErVYLYZ4mvIxvI7ThZdn8MY2RLA5lI-S3KxFHg6T4FY&cl=ffffff" /></a>
      </div>
      <!--      <div class=" my-4 text-left">
    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=0e1633&w=a&t=n&d=ePEQ5JEuRFr0a3FK21KRraTp3IDeAVJ0Rp8hu2BevKc&co=0b4975&cmo=3acc3a&cmn=ff5353&ct=cdd4d9'></script>
  </div> -->
      <!-- Content Row -->
      <!-- /.row -->

    </div>
    <!-- /.container -->

    <!-- Footer -->
    <footer class="py-5 bg-dark">
      <div class="container">
        <p class="m-0 text-center text-white">Designed via Bootstrap</p>
      </div>
      <!-- /.container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
    <!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=ErVYLYZ4mvIxvI7ThZdn8MY2RLA5lI-S3KxFHg6T4FY&cl=ffffff&w=a"></script> -->

  </body>




  
</html>
