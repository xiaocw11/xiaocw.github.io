<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="University of Wisconsin, Madison">
    <meta name="author" content="Chaowei Xiao">

    <title>Chaowei Xiao, University of Wisconsin, Madison</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/small-business.css" rel="stylesheet">
    <style type="text/css">
      .content{margin-top: 0; margin-bottom: 0}
    </style>
    <meta http-equiv="Content-Type" content="text/html; charset=gbk"> 
    <meta name="google-site-verification" content="qEih9m0y-6X0QuisQYfHSxOvkW-o5Q3dfxuQ5Z4JtGA" />

  </head>

  <body>

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
      <div class="container">
        <a class="navbar-brand" href="#">Home</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item active">
              <a class="nav-link" href="#">Home
                <span class="sr-only">(current)</span>
              </a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#about">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="https://xiaocw11.github.io/full.html">Publications</a>
            </li>
          
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Content -->
    <div class="container">

      <!-- Heading Row -->
      <div class="row my-4">
        <div class="col-lg-4">
          <img class="img-fluid rounded img-responsive" style="width:80%" src="img/avatar_new.jpg" alt="">
        </div>
        <!-- /.col-lg-8 -->
        <div class="col-lg-8">
          <h3>Chaowei Xiao </h3>
          <!-- <p>PhD Candidate</p>
          <p>Room 3944, Beyster Building</p>
          <p>2260 Hayward Street, Ann Arbor, Mi 48109</p>
           -->
          <p>Email: cxiao34@wisc.edu</p>
          <p class=" m-0">I am Chaowei Xiao, an assistant professor at the University of Wisconsin, Madison, and  a <a href="https://research.nvidia.com/labs/avg/"> research scientist at NVIDIA </a>.
            
            <!-- I obtained my PhD degree from  University of Michigan, Ann Arbor under supervision of Professor <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> . I obtained my bachelor's degree in School of Software from Tsinghua University in 2015.  -->
            <!-- advised by Professor <a href="http://www.cse.msu.edu/~liuyunha/">Yunhao Liu</a>, Professor <a href="http://www.thss.tsinghua.edu.cn/publish/soft/3641/2013/20130711150050931989171/20130711150050931989171_.html">Zheng Yang</a> and Dr. <a href="http://www4.comp.polyu.edu.hk/~csyanglei/#/pages/profile/about">Lei Yang</a>.  -->
            <!-- I was also a visiting student at UC Berkeley in 2018, advised by Professor <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p> -->
          <p></p>
          <p class="m-0">I am currently very interested in exploring the safety and security of Large Language Model Systems and studying the role of LLMs in different application domains. </p>
          <!-- <p class="m-0" style="color:red">I am on the job marketing.</p> -->
          <br>
          <!-- <p class="m-0"> <font color='red' >I will be joining Arizona State University  as  an assistant professor in the  School of Computing, Informatics, and Decision Systems Engineering in the Fall of 2021. </font> </p> -->

          <!-- <p class="m-0"><a href="https://scholar.google.com/citations?user=Juoqtj8AAAAJ&hl=en">[Google Scholar] </a><a href="pdf/cv_chaoweixiao_new.pdf">[CV] </a></p> -->
          <p class="m-0"> I obtained my Ph.D. from  the University of Michigan, Ann Arbor, and my bachelor's degree from Tsinghua University. Before joining UW-Madison, I spent two years at NVIDIA as a full-time research scientist and a wonderful year at ASU. 
             <!-- Professor <a href="http://www.thss.tsinghua.edu.cn/publish/soft/3641/2013/20130711150050931989171/20130711150050931989171_.html">Zheng Yang</a> and Dr. <a href="http://www4.comp.polyu.edu.hk/~csyanglei/#/pages/profile/about">Lei Yang</a>.  -->
          </p>
          <p class="m-0"><a href="https://scholar.google.com/citations?user=Juoqtj8AAAAJ&hl=en">[Google Scholar] </a> <a href="https://safolab-wisc.github.io/"> [Group Website]</a></p>
          <p> <font color='blue' >
            
            Iâ€™m looking for self-motivated students (B.S., Master, and Ph.D.) who are interested in my research. If you are interested in working with me, drop me an email with your CV. Check out our PhD programs at <a href="https://guide.wisc.edu/graduate/computer-sciences/computer-sciences-phd/"> Computer Science </a>  or  <a href="https://ischool.wisc.edu/programs/phd/"> Information School </a> @ University of Wisconsin Madison and mention my name in your application and research statement.  
  
          </font></p> 
          <p> <font color='red' >
          Our group plans to recruit at least 2-3 PhD students in the coming years with full financial  support.
   </font></p> 
          </font></p> 
           <p> <font color='blue' >
          UW-Madison is an excellent place for research, and Madison is a wonderful city to live in. Please check out these videos (Why <a href="https://www.youtube.com/watch?v=8cRE4F8GOBE">UW-Madison</a>,<a href="https://www.youtube.com/watch?v=XTJA5alrisQ?"> Madison</a>).
   </font></p> 
          </font></p> 

          <br>
          <!-- <a class="btn btn-primary btn-lg" href="#">Call to Action!</a> -->


<!-- Due to the large amount of emails I receive, I may not be able to respond to each one individually. -->
        </div>
        <!-- /.col-md-4 -->
      </div>
      <!-- /.row -->
    <div class=" my-4 text-left">
      <h4>Recent News</h4>
      <ul>
        <li style="display:none "> <a href="cv_chaoweixiao_Feb.pdf">package</a> </li>
        <li style="display:none "> <a href="package_ChaoweiXiao.pdf">package</a> </li>

             <li> [08/2024] We got USENIX Security Distinguished Paper Award. </li>
            <li> [12/2024] I have been selected as <a href="https://ai2050.schmidtsciences.org/fellows/" > Schmidt Science AI2050 Early Career Fellow</a> .  Thank you, Schmidt Science.  </li>
                   <li> [12/2024] I will give an invited talk at SFU@NeurIPS and  LLM and Agent Safety Competition at NeurIPS.</li>
            <li> [12/2024] We got Fall Research Competition Award at UW-Madison. Thank you UW-Madison and OVCR. </li>
                     <li> [11/2024] Our group recently received funding and donations. Thank you Amazon and Apple. </li>
                  <li>[11/2024] Our lab will have a winter break this Dec. Lab members will  enjoy some well-deserved vacation time, with their families and loved ones.  </li> 
                    <li> [10/2024] I will be at Alignment workshop at Bay Area  </li>
                     <li> [10/2024] I will give a keynote at <a href="https://lamps-ccs.com/">CCS Workshop on
Large AI Systems and Models with Privacy and Safety Analysis</a>. Please ping me if you want to chat. </li>
                     <li> [10/2024] I will give an invited talk at Trillion Parameter Consortium (TPC)</li>
                     <li> [10/2024] I will give a talk at <a href="https://nyu-larx.github.io/nsf-llm4security/#Agenda">NSF Workshop on Large Language Models for Network Security  </a></li>
             <li> [09/2024] We have four papers at NeurIPS regular track.</li>
             <li> [09/2024]Our study on  <a href="https://arxiv.org/abs/2402.01920"> safety of RLFH Alignment  </a> is accepted to S&P (Oakland) 2025 </li>

             <li> [07/2024] <a href="https://eddyluo1232.github.io/JailBreakV28K/">MultiModal jailbreak benchmark </a> is accepted to COLM. It is from the interns at my group.  </li>

     <li> [07/2024] 4/4 papers are accepted to ECCV on the topic of trustworthy VLM and driving. Two of them are from  interns in my group.  </li>
        <li> [06/2024] Senior Area Chair for NeurIPS Benchmark track</li>
        <li> [06/2024] I am currently serving as AC for the NeurIPS regular track </li>
        <li> [06/2024] I will give a talk: Security in the era of Vision Large Language Models at CVPR workshop</li>
        <li> [06/2024] I will give a talk: Security in the era of  Large Language Models at NAACL tutorial </li>
        <li> [05/2024] I will give a talk : Security in the era of  Large Language Models at ICLR workshop </li>
        <li> [05/2024] Our jailbreak paper is accepted to USENIX Security. Congratulations, Zhiyuan! </li>
        <li> [03/2024] Five papers at NAACL on LLM security (4 main and 1 finding): two on the backdoor attack, one on backdoor defense, one on jailbreak attacks, and one on model fingerprint.  Stay tuned on these exciting fields </li>
        <li> [03/2024] PreDa for personalized federated learning is accepted at CVPR 2024. </li>      
        <li> [01/2024] Three papers at ICLR. </li>
           <li> [01/2024] Two papers at TMLR </li>
         <li> [12/2023] Invited Talk at NeurIPS TDW workshop </li>
      
        <li> [10/2023]Our paper MoleculeSTM has been accepted to Nature Machine Intelligence. MoleculeSTM aims to align the nature language and molecule representation into the same representation space.  </li> 
                 <details>
            <summary>More</summary>
        <li> [10/2023] Three papers at EMNLP and one paper at NeurIPS. For our NeurIPS paper, we study a new threat of the instruction tuning of LLMs by injecting the Ads. This is the first work that views the LLMs as the generative model and aims  to attack the generative property of LLMs.  </li> 
         <li> [10/2023] Our tutorial on Security and Privacy in the Era of Large Language Models is accepted to NAACL.  </li> 
        <li> [05/2023] One paper at ACL.  Congratulations to zhuofeng and jiazhao. We propose an attention-based method to defend against NLP backdoor attacks </li>
        <li> [04/2023] Two papers at ICML. Congratulations to Jiachen and Zhiyuan. We propose the first benchmark for code copyright of code generation models.</li>
        <li> [02/2023] Two papers at CVPR. Congratulations to Yiming and Xiaogeng. Xiaogeng is an intern from my group at ASU. </li>
        <li> [02/2023] I will give a tutorial at CVPR 2023 on the topic of trustworthiness in the era of Foundation Models. Stay tuned!</li>
        <li> [01/2023] <a href="impact.pdf">Impact Award from Argonne National Laboratory.</a> </li>
        <li> [01/2023] One paper got accepted to USENIX Security 2023. </li>
        <li> [1/2023] Three papers are accepted to ICLR 2023 <a href="https://arxiv.org/abs/2211.00322">[a]: </a>We explain why and how to use diffusion model to improve adversarial robustness and design DensePure which leverages the pretrained diffusion model and classifier to provide the state-of-the-art certified robustness. <a href="https://arxiv.org/pdf/2208.11126.pdf">[b]:</a>This is our first attemp on  retrieval-based framework and AI for drug discovery. We will recently release more work in this research line. Stay tuned! </li>
        <li> [12/2022] Our team won the ACM Gordon Bell Special Prize for COVID-19 Research.</li>
        <li> [09/2022] One papers got accepted to USENIX Security 2023.</li>
        <li> [09/2022] Two papers got accepted to  NeurIPS 2022.</li>
        <li> [09/2022] Our paper <a href="https://arxiv.org/pdf/2208.00094.pdf">RobustTraj</a> has been accepted to CORL for oral presentations. We explore to train a robust Trajectory Prediction Model against adversarial attacks.</li>
 
        <li> [08/2022] I will be giving a talk in virtual seminar series on 
          <a href="https://vsehwag.github.io/SPML_seminar/" > Challenges and Opportunities for Security & Privacy in Machine Learning.</a>
        <li> [07/2022] One survey paper to discuss the challenge and opportunity of machine learning security got accepted to ACM Computing Survey 2022.  
        <li> [07/2022] Two papers got accepted to ECCV 2022.  </li>
        <li> [05/2022] Two papers got accepted to ICML 2022. Thanks for all of my collaborators. </li>
        <li> [3/2022]  I will be giving a talk in AAAI 2022 1st International Workshop on Practical Deep Learning in the Wild.</li>
        <li> [3/2022] I will be giving a talk in AAAI 2022 workshop on Adversarial Machine Learning and Beyond. </li>

          <li> [2/2022] One paper is accepted to ICLR. </li>
      </details>
    </ul>
      <!-- <p> [07/2019]: Our paper "AdvIT: Adversarial Frames Identifier Based on Temporal Consistency In Videos" is accepted to ICCV 2019. </p>  -->
         <!-- <p>  [06/2019]: Our paper: <a href="https://arxiv.org/abs/1907.05418"> "Adversarial Objects Against LiDAR-Based Autonomous Driving Systems" </a> is reported by <a href="https://syncedreview.com/2019/07/18/researchers-fool-lidar-with-3d-printed-adversarial-objects/"> Syncedreview</a>, <a href="https://www.selfdrivingcars360.com/researchers-fool-lidar-with-3d-printed-adversarial-objects/">Selfdrivingcars360</a>, <a href="https://www.analyticsindiamag.com/lidar-adversarial-objects-research-vulnerabilities-drawbacks/amp/">Analytics</a> and is discussed at <a href="https://www.reddit.com/r/SelfDrivingCars/comments/cc7khu/adversarial_objects_against_lidarbased_autonomous/">Reddit [1]</a>, <a href="https://www.reddit.com/r/MachineLearning/comments/ccc7p4/r_we_also_3dprint_our_adversarial_objects_and/">[2]</a>.</p> -->
      <!-- <p> [05/2019]: One paper is accepted to CCS 2019. </p>  -->
      <!-- <p> [05/2019]: One paper is accepted to USENIX Security 2019.  </p>  -->

<!--       <p> [03/2019]: I will serve as a Program Committee member of <a href="https://icml2019workshop.github.io/">Security and Privacy of Machine Learning workshop </a> at ICML 2019.</p>  
 -->
      </div>

<!--     <div class="my-4 text-left">    
      <h4>Current PhD Students:</h4>  
       <ul>
            <li><a href="https://jiongxiao-wang.github.io/"> Jiongxiao Wang </a> </li>
            <li><a href="https://sheltonliu-n.github.io/"> Xiaogeng Liu</a></li>
            <li><a href="https://cychomatica.github.io/"> Shutong Wu </a></li>
            <li><a href=""> Fangzhou Wu</a> </li>
        </ul>
   
    </div> -->
<!--     <div class="my-4 text-left">    
      <h4> Research Overview</h4>  
      <img class="col-lg-8" src="framework.png" alt="research overview">
    </div> -->
      <!-- Call to Action Well -->
<!--       <div class=" my-4 text-left">
          <h4 id="about">About</h4>
          <p class=" m-0">I am<strong>Chaowei Xiao</strong>, a final year PhD student in CSE Department, University of Michigan, Ann Arbor. My advisor is Professor <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> . I obtained my bachelor's degree in School of Software from Tsinghua University in 2015, advised by Professor <a href="http://www.cse.msu.edu/~liuyunha/">Yunhao Liu</a>, Professor <a href="http://www.thss.tsinghua.edu.cn/publish/soft/3641/2013/20130711150050931989171/20130711150050931989171_.html">Zheng Yang</a> and Dr. <a href="http://www4.comp.polyu.edu.hk/~csyanglei/#/pages/profile/about">Lei Yang</a>. I was also a visiting student at UC Berkeley in 2018, advised by Professor <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a> and Professor <a href="http://boli.cs.illinois.edu/">Bo Li</a>. </p>
          <p></p>
          <p class="m-0">My research interest includes adversarial machine learning. </p>


      </div> -->
      <!-- <div class="my-4 text-left">
        <h4>Current Students (Collaborators) </h4>
        <ul>
            <li><a href=""> Yulong Cao </a> (affiliated Ph.D. student from University of Michigan, Ann Arbor)</li>
            <li><a href=""> Jiachen Sun</a> (affiliated Ph.D. student from University of Michigan, Ann Arbor)</li>
            <li><a href=""> Haizhong Zheng </a> (affiliated Ph.D. student from University of Michigan, Ann Arbor)</li>
            <li><a href=""> Jiazhao Li </a> (affiliated Ph.D. student from University of Michigan, Ann Arbor)</li>
        </ul>
      </div>
      <div class="my-4 text-left">
        <h4>Past Students</h4>
        <ul>
            <li><a href=""> Zichao Li</a> (now Ph.D. student from UCSC)</li>
            <li><a href=""> Haonan Qiu</a> (now Ph.D. student from NTU)</li>
        </ul>
      </div> -->



   <div class=" my-4 text-left">      
<!-- <div class="card-body"> -->
          <h4 id="pub"> Preprints </h4>
       <ul>

                       <li><b> [New][LLM System Security] A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems. </b><p class='content'> Fangzhou Wu, Ning Zhang, Somesh Jha, Patrick McDaniel, Chaowei Xiao. </p><a href="https://arxiv.org/abs/2402.18649">https://arxiv.org/abs/2402.18649</a></li>
 

       </ul>
         <h4 id="pub"> Publications (Selected) </h4>
           <p>(* represents equal contribution) </p>
           <p><a href="full.html">[Full List]</a>, <a href="https://scholar.google.com/citations?user=Juoqtj8AAAAJ&hl=en">[Google Scholar]</a></p>
      <!-- <h5> 2023</h5> -->
         <ul>

                <li><b>[New][LLM Security] Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment.  </b> <p class='content'> Jiongxiao Wang, Jiazhao Li, Yiquan Li, Xiangyu Qi, Muhao Chen, Junjie Hu, Yixuan Li, Bo Li, Chaowei Xiao
</p> <a href="https://arxiv.org/abs/2402.14968">NeurIPS 2024</a> </li>
         <li><b>[LLM For Driving] Dolphins: Multimodal Language Model for Driving.  </b> <p class='content'>  Yingzi Ma, Yulong Cao, Jiachen Sun, Marco Pavone, Chaowei Xiao</p> <a href="https://arxiv.org/abs/2312.00438"> ECCV 2024</a> </li>     

       <li><b> [ Embodied Agent] Voyager: An Open-Ended Embodied Agent with Large Language Models.  </b> <p class='content'>  Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, Anima Anandkumar
</p> <a> TMLR 2024</a> </li>     

            <li><b>[LLM Fingerprint]Instructional fingerprinting of large language models.  </b> <p class='content'>  Jiashu Xu, Fei Wang, Mingyu Derek Ma, Pang Wei Koh, Chaowei Xiao, Muhao Chen.</p> <a href="https://arxiv.org/abs/2401.12255">NAACL 2024.</a> </li>

            <li><b>[LLM Safety]AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models.  </b> <p class='content'>  Xiaogeng Liu, Nan Xu, Muhao Chen, Chaowei Xiao.</p> <a href="https://arxiv.org/pdf/2310.04451.pdf">ICLR 2024.</a> </li>

          <li><b>[LLM Safety]On the exploitability of instruction tuning.  </b> <p class='content'>  Manli Shu, Jiongxiao Wang, Chen Zhu, Jonas Geiping, Chaowei Xiao*, Tom Goldstein*. <p>NeurIPS   2023 <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
          <li><b>[LLM Copyright]CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models          </b> <p class='content'> Zhiyuan Yu, Yuhao Wu, Ning Zhang, Chenguang Wang, Yevgeniy Vorobeychik, <strong>Chaowei Xiao</strong><p>ICML   2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
          <li><b>  [Diffusion & Security] Diffusion Models for Adversarial Purification</b> <p class='content'>Weili Nie, Brandon Guo, Yujia Huang,<strong>Chaowei Xiao</strong>, Arash Vahdat, Anima Anandkumar. <p>ICML 2022<a href="https://arxiv.org/abs/2205.07460">[pdf]</a> <a href="https://github.com/NVlabs/DiffPure">[code]</a></p></p></li>         
         <li><b>[Diffusion & Security]  DensePure: Understanding Diffusion Models towards Adversarial Robustness. </b> <p class='content'>  <strong>Chaowei Xiao</strong>*, Zhongzhu Chen*, Kun Jin*, Jiongxiao Wang*, Weili Nie, Mingyan Liu, Anima Anandkumar, Bo Li, Dawn Song  <p>ICLR  2023. <a href="">[pdf]</a> <a href="">[code]</a></p></p></li>
           
 
          
          <li><b>  [ViT & Robustness] Understanding the robustness in vision transformers.</b> <p class='content'>Daquan Zhou, Zhiding Yu, Enze Xie,<strong>Chaowei Xiao</strong>, Anima Anandkumar, Jiashi Feng, Jose M Alvarez.<p>ICML 2022<a href="https://arxiv.org/abs/2204.12451">[pdf]</a> <a href="https://github.com/NVlabs/FAN">[code]</a></p></p></li>
          
<!-- 
          <li><b> [Security] AdvDO: Realistic Adversarial Attacks for
            Trajectory Prediction</b> <p class='content'>Yulong Cao,<strong>Chaowei Xiao</strong>, Anima Anandkumar, Danfei Xu,
              Marco Pavone.<p>ECCV 2022<a href="">[pdf]</a> <a href="">[code]</a></p></p></li> -->


          <!-- <li><b> SecretGen: Privacy Recovery on Pre-trained Models</b> <p class='content'>Zhuowen Yuan, Fan Wu, Yunhui Long,<strong>Chaowei Xiao</strong>, Bo Li<p>ECCV 2022<a href="">[pdf]</a> <a href="">[code]</a></p></p></li> -->
          
     


          <!-- <li><b>[Robustness] RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning</b><p class='content'> Xiaojian Ma, Weili Nie, Zhiding Yu, Huaizu Jiang,<strong>Chaowei Xiao</strong>, Yuke Zhu, Song-Chun Zhu, Anima Anandkumar <p>ICLR 2022<a href="https://web.cs.ucla.edu/~xm/file/relvit_iclr22.pdf">[pdf]</a> <a href="https://github.com/NVlabs/RelViT">[code]</a></p></p></li> -->
          
          <!-- <li><b> Characterizing Attacks on Deep Reinforcement Learning. </b> <p class='content'>Xinlei Pan*,<strong>Chaowei Xiao</strong>*, Warren He, Shuang Yang, Peng Jian, Mingjie Sun, Mingyan Liu, Bo Li, Dawn Song.  <p>AAMAS 2022 <a href="pdf/aamas_2022.pdf">[pdf]</a></p></p></li> -->

            <!-- </ul> -->
          <!-- <h5>2021</h5> -->
          <!-- <ul> -->
          <li><b>[Robustness] AugMax: Adversarial Composition of RandomAugmentations for Robust Training. </b> <p class='content'>Haotao Wang,<strong>Chaowei Xiao</strong>, Jean Kossaifi, Zhiding Yu, Animashree Anandkumar,  Zhangyang Wang.  <p>NeurIPS 2021</p></p></li>
         
          <!-- <li><b> Efficient Transformers for Language and Vision. </b> <p class='content'>Chen Zhu, Wei Ping,<strong>Chaowei Xiao</strong>, Mohammad Shoeybi, Tom Goldstein, Anima Anandkumar, Bryan Catanzaro. <p>NeurIPS 2021 (84.1% Top-1 accuracy solely trained on ImageNet-1K)</p></p></li> -->
                  
          <!-- <li><b> Can Shape Structure Features Improve Model Robustness? </b> <p class='content'>Mingjie Sun*, Zichao Li*,<strong>Chaowei Xiao</strong>*, Haonan Qiu, Bhavya Kailkhura, MingyanLiu, Bo Li. <p>ICCV 2021</p></p></li> -->
           
           <li><b> [Security] Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion based Perception in Autonomous Driving Under Physical-World Attacks.</b> <p class='content'>Yulong Cao*, Ningfei Wang*,<strong>Chaowei Xiao</strong>*, Dawei Yang*, Jin Fang, RuigangYang, Qi Alfred Chen, Mingyan Liu, Bo Li. <p>IEEE Symposium on Security and Privacy (Oakland) 2021</p></p></li>
           <!-- Yulong Cao, Ningfei Wang,<strong>Chaowei Xiao</strong>, Dawei Yang, Jin Fang, RuigangYang, Qi Alfred Chen, Mingyan Liu, Bo Li.  (IEEE Symposium on Security and Privacy (Oakland), 2021 -->
           <!-- <li><b>  Behavior Privacy Perserving in RF Sensing.</b> <p class='content'>Jianwie Liu,Chaowei Xiao, Kaiyan Cui, Jinsong Han, Xian Xu, Kui Ren. <p> IEEE Transcations on Dependable and Secure Computing. <a href="pdf/TDSC.pdf">[pdf]</a></p></p></li> -->
           <!-- </ul> -->
           <!-- <h5>2020</h5> -->
           <!-- <ul> -->
           <!-- <li><b>[Security] SemanticAdv: Generating Adversarial Examples via Attribute-conditional Image Editing</b><p class='content'> Haonan Qiu*, <strong>Chaowei Xiao*</strong>, Lei Yang*, Xinchen Yan, Honglak Lee,  Bo Li.  <p>ECCV 2020</p></p> -->
     
            <!-- <li><b>[Security] Towards Stable and Efficient Training of Verifiably Robust Neural Networks</b><p class='content'> Huan Zhang, Hongge Chen, <strong>Chaowei Xiao</strong>, Sven Gowal, Robert Stanforth, Bo Li, Duane Boning, Cho-Jui Hsieh.  <p>ICLR 2020.</p></p>
            </li> -->
            <!-- </ul> -->
            <!-- <h5>2019</h5> -->
            <!-- <ul> -->
      <!-- <li><b>AdvIT: Adversarial Frames Identifier Based on Temporal Consistency In Videos</b><p class='content'> <strong>Chaowei Xiao</strong>, Ruizhi Deng, Bo Li, Taesung Lee, Jinfeng Yi, Ian Molloy, Mingyan Liu, Dawn Song</p>
            <p>In International Conference on Computer Vision (ICCV) 2019.</p>
             </li> -->


    <!-- <li><b>Performing Co-Membership Attack Against Deep Generative Model</b><p class='content'> Kin Sum Liu, <strong> Chaowie Xiao </strong>, Bo Li, Jie Gao</p> <p>In IEEE International Conference on Data Mining (ICDM) 2019</p></li> -->
    <!-- <li><b>Improving Robustness of ML Classifiers against Realizable Evasion Attacks Using Conserved Features</b><p class='content'> Liang Tong, Bo Li, Chen Hajaj, <strong>Chaowei Xiao</strong>, Ning Zhang, Yevgeniy Vorobeychik.</p> -->
    <!-- <p>In USENIX Security 2019. </p> -->
    <!-- </li> -->
  
  <!-- </ul> -->
  <!-- <h5>2018</h5> -->
  <!-- <ul> -->
  <!-- <li><b>Characterizing Adversarial Examples Based on Spatial Consistency Information for Semantic Segmentation</b>
    <p class="content"><strong>Chaowei Xiao</strong>, Duizhi Deng, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, <a href="http://www.yf.io/">Fisher Yu</a>, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p class="">In European Conference on Computer Vision (ECCV), 2018 <a href="pdf/ECCV_CR_1682.pdf">[pdf]</a><a href="pdf/1682_supp.pdf">[supplementary material]</a>

    </p> -->
  </li>
  <li><b>[Security] Spatially Transformed Adversarial Examples</b>
    <p class="content"><strong>Chaowei Xiao*</strong>, <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu*</a>, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, Warren He, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p class="">In International Conference on Learning Representations (ICLR), 2018 <a href="https://arxiv.org/abs/1801.02612">[pdf]</a>

    </p>
  </li>
  <li><b>[Security] Generating Adversarial Examples with Adversarial Networks</b>
    <p class="content"><strong>Chaowei Xiao</strong>, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu</a>, Warren He, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p>In International Joint Conference on Artificial Intelligence (IJCAI), 2018. <a href="https://arxiv.org/abs/1801.02610">[pdf]</a>

  </p>
  </li>
  <!-- <li><b>From Behavior Similarity to Symptom Similarity: Using Community Detection for Early Discovery of Software Exploits</b>
    <p class="content"><strong>Chaowei Xiao</strong>, Armin Sarabi,<a href="http://www-personal.umich.edu/~youngliu/">Yang Liu </a>, <a href="http://boli.cs.illinois.edu">Bo Li</a>, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="http://legacydirs.umiacs.umd.edu/~tdumitra/">Tudor Dumitras</a></p>
    <p>In USENIX Security Symposium (USENIX Security), 2018 <a href='pdf/sec18-final415.pdf'>[pdf]</a>
    </p>
  </li> -->
 <li><b>[Security] Robust Physical-World Attacks on Machine Learning Models</b>
    <p class="content"> Kevin Eykholt*, <a href="https://ivanevtimov.eu/">Ivan Evtimov*</a>, <a>Earlence Fernandes</a>, <a href="http://boli.cs.illinois.edu/">Bo Li</a>, <a href="https://amir.rahmati.com/">Amir Rahmati</a>, <strong>Chaowei Xiao</strong>,  <a href="http://web.eecs.umich.edu/~aprakash/">Atul Prakash</a>,  <a href="https://homes.cs.washington.edu/~yoshi/">Tadayoshi Kohno</a> and <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p><p>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018 <a href="https://arxiv.org/abs/1707.08945">[pdf]</a>

  </p>
  </li>
  <!-- <li><b>Patch Me If You Can: A Study on the effects of Individual User Behavior on the End-Host Vulnerability State</b>
    <p class="content">Armin Sarabi, Ziyun Zhu, <strong>Chaowei Xiao</strong>, <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a> and <a href="http://legacydirs.umiacs.umd.edu/~tdumitra/">Tudor Dumitras</a></p>
    <p>In Passive and Active Measurement conference (PAM), 2017 <a href="http://web.eecs.umich.edu/~mingyan/pub/PAM17_102-Sarabi.pdf">[pdf]</a>

    </p>
  </li> -->
<!-- </ul>
<h5>Before 2018</h5>
<ul>
  <li><b>Static Power of Mobile Devices: Self-updating Radio Maps for Wireless Indoor Localization</b>
    <p class="content"><a href="http://cswu.me/">Chenshu Wu</a>, <a href="http://www.tsinghua.edu.cn/publish/soften/3131/2013/20130711152929220429684/20130711152929220429684_.html">Zheng Yang</a>, <strong>Chaowei Xiao</strong>, Chaofan Yang, <a href="http://www.cse.msu.edu/~liuyunha/">Yunhao Liu</a> and <a href="http://web.eecs.umich.edu/~mingyan/">Mingyan Liu</a>
    <p>In IEEE International Conference on Computer Communications (INFOCOM), 2015
    </p> 
  </li>
  <li><b>Tagoram: Real-time Tracking of Mobile RFID Tags to High Precision Using COTS Devices.</b>
    <p class="content"><a href="http://www4.comp.polyu.edu.hk/~csyanglei/">Lei Yang</a>, Yekui Chen, <a href="http://www.cs.iit.edu/~xli/">Xiangyang Li</a>, <strong>Chaowei Xiao</strong>, <a href="https://www.ntu.edu.sg/home/limo/">Mo Li</a> and <a href="http://www.cse.msu.edu/~liuyunha/">Yunhao Liu</a> </p>
    <p>In International Conference on Mobile Computing and Networking (MobiCom), 2014. <span style="color:#FF3333;"">Best Paper Award</span> -->

    </p>
  </li>
 <!--  <li><b>Automatic Radio Map Adaptation for Indoor Localization using Smartphones</b>
        <p class="content"><a href="http://cswu.me/">Chenshu Wu</a>, <a href="http://www.tsinghua.edu.cn/publish/soften/3131/2013/20130711152929220429684/20130711152929220429684_.html">Zheng Yang</a> and <strong><strong>Chaowei Xiao</strong></strong>,</a>
    <p>In IEEE Transactions on Mobile Computing (TMC) 2017
    </p>
  </li>
 -->

</ul>


          
        <!-- </div> -->
      </div>
      <div class="my-4 text-left">
      <a href="https://clustrmaps.com/site/1bjs5"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=ErVYLYZ4mvIxvI7ThZdn8MY2RLA5lI-S3KxFHg6T4FY&cl=ffffff" /></a>
      </div>
      <!--      <div class=" my-4 text-left">
    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=0e1633&w=a&t=n&d=ePEQ5JEuRFr0a3FK21KRraTp3IDeAVJ0Rp8hu2BevKc&co=0b4975&cmo=3acc3a&cmn=ff5353&ct=cdd4d9'></script>
  </div> -->
      <!-- Content Row -->
      <!-- /.row -->

    </div>
    <!-- /.container -->

    <!-- Footer -->
    <footer class="py-5 bg-dark">
      <div class="container">
        <p class="m-0 text-center text-white">Designed via Bootstrap</p>
      </div>
      <!-- /.container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
    <!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=ErVYLYZ4mvIxvI7ThZdn8MY2RLA5lI-S3KxFHg6T4FY&cl=ffffff&w=a"></script> -->

  </body>




  
</html>
